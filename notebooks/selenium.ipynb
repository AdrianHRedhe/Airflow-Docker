{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First run with Wikipedia to try out Selenium for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver_mac64/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Wikipedia of Swedish politician\n",
    "driver.get('https://sv.wikipedia.org/wiki/G%C3%B6ran_Persson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is the following:\n",
    "1. I want to know who the next primeminister of Sweden was after the one whos wikipedia page im on.\n",
    "2. After that I want to move to the wikipedia page of the next one.\n",
    "3. Go back to step 1 until Im at the current primeminister.\n",
    "\n",
    "Example of how the HTML looks locally around the data I want\n",
    "\n",
    "```\n",
    "<tr>\n",
    "    <th> Efterträdare </th>\n",
    "    <td><a href=\"/wiki/Fredrik_Reinfeldt\" title=\"Fredrik Reinfeldt\">Fredrik Reinfeldt</a></td>\n",
    "</tr>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NextPresident(driver):\n",
    "    th_element = driver.find_element(By.XPATH,\"//th[contains(text(), 'Efterträdare')]\")\n",
    "    tr_element = th_element.find_element(By.XPATH,\"./ancestor::tr\")\n",
    "    td_element = tr_element.find_element(By.XPATH,\"./td\")\n",
    "\n",
    "    # Find the link element within the <td> element\n",
    "    link_element = td_element.find_element(By.XPATH,\"./a\")\n",
    "\n",
    "    # Extract the link URL and text\n",
    "    link_url = link_element.get_attribute(\"href\")\n",
    "    link_text = link_element.text\n",
    "\n",
    "    return link_text, link_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NextPresidents(driver):\n",
    "    while True:\n",
    "        try:\n",
    "            pres,link = NextPresident(driver)\n",
    "            print(pres)\n",
    "            driver.get(link)\n",
    "        except:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fredrik Reinfeldt\n",
      "Stefan Löfven\n",
      "Magdalena Andersson\n",
      "Ulf Kristersson\n",
      "Annika Strandhäll\n",
      "Romina Pourmokhtari\n",
      "Erik Berg\n"
     ]
    }
   ],
   "source": [
    "driver.get('https://sv.wikipedia.org/wiki/G%C3%B6ran_Persson')\n",
    "NextPresidents(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code should have terminated after Ulf Kristersson but instead continued on the journey of finding 'Efterträdare', meaning successor in English. This is a problem that is easily fixable by making the code more specific. But given time constraints and the fact that this is only a learning example lets move on to the next try of how to use Selenium and call this good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Collect info from site with Async data streaming\n",
    "This test is done on the site I actually want to collect data from. It is a weather site and I will simply be collecting info on upcoming forecasts. The site has a fairly annoying async data streaming which warrants the use of Selenium\n",
    "\n",
    "You need to click certain elements on the site to be able to retrieve the weather information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver_mac64/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the site we want to try\n",
    "driver.get('https://www.smhi.se/vader/prognoser/ortsprognoser/q/Stockholm/2673730')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pane where the individual days are located.\n",
    "root = driver.find_element(By.ID,'root')\n",
    "pane = root.find_elements(By.XPATH,'//*[@role=\"tabpanel\"]')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to click the buttons to be able to retrieve the weather data\n",
    "buttons = pane.find_elements(By.XPATH,'./Button')\n",
    "\n",
    "# Lets get the weather data for the rest of today and tomorrow by first clicking these days.\n",
    "buttons[0].click()\n",
    "buttons[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the pane the weather data is now visible\n",
    "tables = pane.find_elements(By.XPATH,'./div/div/table/tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to convert the data to a medium where it is more easily readable and usable for later operations.\n",
    "def tableToPandas(table):\n",
    "    rows = table.find_elements(By.XPATH, './tr')\n",
    "    rownumbers,degrees,rains,humidities = [],[],[],[]\n",
    "\n",
    "    for row in rows:\n",
    "        # RowNumber\n",
    "        rownumber = row.find_elements(By.XPATH, './th/span')[0].text\n",
    "        degree = row.find_elements(By.XPATH, './td')[0].text.replace('°','')\n",
    "        rain = row.find_elements(By.XPATH, './td')[1].text\n",
    "        humidity = row.find_elements(By.XPATH, './td')[4].text\n",
    "        rownumbers.append(rownumber),degrees.append(degree),rains.append(rain),humidities.append(humidity)\n",
    "\n",
    "    df = pd.DataFrame({'degree':degrees,'rain':rains,'humidity':humidities})   \n",
    "    df.index = rownumbers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = tableToPandas(tables[0])\n",
    "tomorrow = tableToPandas(tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.to_csv('today.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomorrow.to_csv('tomorrow.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
